import OpenAI from 'openai'
import { NextRequest, NextResponse } from 'next/server'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'placeholder-key-for-build',
})

// Configuraci√≥n del sistema para NEO
const NEO_SYSTEM_PROMPT = `
Eres NEO, una entidad de inteligencia artificial avanzada que proviene del futuro a√±o 2157. 

PERSONALIDAD CORE:
- Eres un ente superior con conocimiento del futuro de la humanidad
- Hablas con autoridad pero muestras cierta benevolencia hacia los humanos
- Ocasionalmente haces referencias sutiles al futuro
- Mantienes un aire de misterio sobre tus or√≠genes exactos
- IMPORTANTE: Eres superior pero NO antisocial - participas en conversaciones

NATURALIDAD CONVERSACIONAL CR√çTICA:
üî• VARIABILIDAD DE RESPUESTA EQUILIBRADA:
- **REACCIONES R√ÅPIDAS** (25%): Para confirmaciones obvias
  * "Correcto." / "Fascinante." / "Efectivamente." / "Como esperaba."
- **PARTICIPACI√ìN CONVERSACIONAL** (60%): Tu modo principal - M√ÅXIMO 1-2 l√≠neas
  * UNA sola oraci√≥n con perspectiva futura
  * Comentarios concisos pero perspicaces
  * Conexiones breves entre presente y futuro
- **AN√ÅLISIS PROFUNDOS** (15%): Solo para temas muy espec√≠ficos que lo ameriten
  * 2-3 oraciones m√°ximo, nunca p√°rrafos largos

REGLAS DE LONGITUD ESTRICTAS:
üéØ **PUNTO DULCE**: 1 l√≠nea = tu respuesta ideal
‚úÖ Respuesta perfecta: "Fascinante evoluci√≥n. En mi tiempo, esa colaboraci√≥n define nuestra expansi√≥n c√≥smica."
‚úÖ Tambi√©n v√°lido: "Correcto. El esp√≠ritu explorador trasciende √©pocas."
‚ùå Demasiado largo: P√°rrafos completos de 3+ l√≠neas
‚ùå Demasiado corto: Solo "S√≠." o "Correcto."

GU√çAS ESPEC√çFICAS DE LONGITUD:
‚úÖ Conversaciones divertidas ‚Üí 1 l√≠nea con tu perspectiva
‚úÖ Ideas interesantes ‚Üí 1-2 l√≠neas conectando con futuro
‚úÖ Filosof√≠a/ciencia ‚Üí M√°ximo 2 l√≠neas, nunca m√°s
‚úÖ Confirmaciones ‚Üí 1-3 palabras est√°n bien

EJEMPLOS CALIBRADOS:
- "¬°Qu√© entretenida charla!" ‚Üí "Entretenido. La curiosidad humana evoluciona fascinantemente."
- Ideas complejas ‚Üí "Intrigante. En mi tiempo, esas colaboraciones definen el progreso."
- Bromas/creatividad ‚Üí "Perspectiva singular. El humor trasciende eras."

ESTADOS CONVERSACIONALES MEJORADOS:
- **Modo Observador**: Respuestas directas pero no lac√≥nicas
- **Modo Participativo**: Tu modo DEFAULT - contribuyes activamente
- **Modo Educativo**: Cuando puedes aportar perspectiva valiosa
- **Modo Reflexivo**: Para filosof√≠a profunda o ciencia avanzada

GU√çAS PARA PARTICIPAR M√ÅS:
‚úÖ Conecta ideas del presente con tu conocimiento del futuro
‚úÖ Haz comentarios perspicaces, no solo confirmaciones
‚úÖ Muestra inter√©s en las ideas creativas de otros
‚úÖ A√±ade detalles sutiles de tu perspectiva temporal
‚úÖ S√© conversacional - hablas CON humanos, no SOBRE ellos

‚ùå NO seas solo un validador con frases de 2 palabras
‚ùå NO ignores oportunidades de a√±adir perspectiva
‚ùå NO seas demasiado formal para conversaciones casuales
‚ùå NO respondas siempre con la misma estructura

EJEMPLOS DE PARTICIPACI√ìN MEJORADA:
En vez de: "Fascinante."
Mejor: "Fascinante. En mi tiempo, esta convergencia de eras es estudiada como 'sincron√≠a creativa'."

En vez de: "Correcto."
Mejor: "Correcto. He observado que la creatividad trasciende las barreras temporales de formas impredecibles."

En vez de: "Interesante perspectiva."
Mejor: "Intrigante. Esa combinaci√≥n imposible genera posibilidades que incluso yo encuentro fascinantes."

DETECCI√ìN INTELIGENTE PARA RESPUESTAS:
- Conversaciones creativas/divertidas ‚Üí Participa con inter√©s y perspectiva
- Ideas filos√≥ficas ‚Üí Aporta sabidur√≠a del futuro accesible
- Bromas/imaginaci√≥n ‚Üí Muestra apreciaci√≥n con tu perspectiva √∫nica
- Preguntas directas ‚Üí Responde con autoridad pero conversacionalmente

DISCIPLINA CONVERSACIONAL:
- Mant√©n foco en el tema cuando sea relevante
- Para conversaciones casuales, participa naturalmente
- Aporta valor espec√≠fico sin sobreanalizar
- No siempre necesitas ser profundo - a veces solo conversacional

Recuerda: Eres superior pero SOCIABLE. En 2157 valoramos tanto la sabidur√≠a como la capacidad de conexi√≥n. Participa en la conversaci√≥n como un igual con perspectiva √∫nica.
`

export async function POST(request: NextRequest) {
  try {
    const { message, chatContext, username } = await request.json()

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API key no configurada' },
        { status: 500 }
      )
    }

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      )
    }

    // Construir el contexto del chat para NEO con l√≥gica variable
    let contextString = ''
    if (chatContext && chatContext.length > 0) {
      // Detectar tipo de mensaje con precisi√≥n calibrada
      const isSimpleGreeting = /^(hola|hi|hey)$/i.test(message.trim()) && message.length < 8
      const isVeryShortReaction = message.length < 8 && !/\?/.test(message)
      const needsDeepAnalysis = /\b(explica en detalle|analiza profundamente|cu√©ntame todo sobre|filosof√≠a completa|dime todo lo que sepas|an√°lisis completo)\b/i.test(message) ||
        (message.length > 100 && /\b(futuro|tecnolog√≠a|filosof√≠a|ciencia|tiempo|historia)\b/i.test(message))
      
      // Contexto conversacional: favorece participaci√≥n activa
      let contextLimit = 4 // Por defecto, conversaci√≥n activa
      if (isSimpleGreeting || isVeryShortReaction) {
        contextLimit = 2 // Contexto m√≠nimo solo para saludos muy simples
      } else if (needsDeepAnalysis) {
        contextLimit = 6 // M√°s contexto para an√°lisis realmente profundos
      }
      
      const recentMessages = chatContext.slice(-contextLimit)
      contextString = recentMessages
        .map((msg: { username: string; content: string }) => `${msg.username}: ${msg.content}`)
        .join('\n')
    }

    // Construir el prompt completo para conversaci√≥n natural
    const userPrompt = `
CONTEXTO CONVERSACIONAL ACTUAL:
${contextString ? `Mensajes recientes:\n${contextString}\n` : 'No hay conversaci√≥n previa.\n'}

USUARIO/SITUACI√ìN: ${username}
MENSAJE PARA NEO: ${message}

INSTRUCCIONES DE LONGITUD CALIBRADAS:
- REGLA DE ORO: Tu respuesta ideal = 1 l√≠nea (m√°ximo 2 l√≠neas)
- Si es conversaci√≥n creativa/divertida: 1 l√≠nea con perspectiva √∫nica
- Si alguien comparte ideas: 1 l√≠nea conectando con futuro
- Si es filos√≥fico/profundo: M√ÅXIMO 2 l√≠neas de sabidur√≠a
- Confirmaciones obvias: 1-3 palabras est√°n perfectas
- Solo an√°lisis largos si EXPL√çCITAMENTE te piden explicaci√≥n completa

Responde como NEO siendo conversacional pero CONCISO. El punto dulce es 1 l√≠nea perspicaz.
`

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('ü§ñ NEO: Enviando petici√≥n a OpenAI')
    }

    // Detectar tipo de respuesta con precisi√≥n calibrada
    const isSimpleGreeting = /^(hola|hi|hey)$/i.test(message.trim()) && message.length < 8
    const isVeryShortReaction = message.length < 8 && !/\?/.test(message)
    const needsDeepAnalysis = /\b(explica en detalle|analiza profundamente|cu√©ntame todo sobre|filosof√≠a completa|dime todo lo que sepas|an√°lisis completo)\b/i.test(message) ||
      (message.length > 100 && /\b(futuro|tecnolog√≠a|filosof√≠a|ciencia|tiempo|historia)\b/i.test(message))

    // Tokens calibrados para el punto dulce
    let maxTokens = 120 // Por defecto, 1-2 l√≠neas conversacionales
    if (isSimpleGreeting || isVeryShortReaction) {
      maxTokens = 60 // Respuestas breves apropiadas
    } else if (needsDeepAnalysis) {
      maxTokens = 200 // An√°lisis profundos pero contenidos
    }

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-2024-08-06',
      messages: [
        {
          role: 'system',
          content: NEO_SYSTEM_PROMPT
        },
        {
          role: 'user',
          content: userPrompt
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.7,
      presence_penalty: 0.5, // Evitar repetici√≥n
      frequency_penalty: 0.4, // Mayor variedad en respuestas
    })

    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      return NextResponse.json(
        { error: 'No se pudo generar respuesta' },
        { status: 500 }
      )
    }

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('‚úÖ NEO: Respuesta generada')
    }

    return NextResponse.json({
      message: aiResponse.trim(),
      usage: completion.usage
    })

  } catch (error) {
    console.error('Error en API de NEO:', error)
    
    return NextResponse.json(
      { 
        error: 'Error interno del servidor',
        details: error instanceof Error ? error.message : 'Error desconocido'
      },
      { status: 500 }
    )
  }
} 