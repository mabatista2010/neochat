import OpenAI from 'openai'
import { NextRequest, NextResponse } from 'next/server'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'placeholder-key-for-build',
})

// Configuraci√≥n del sistema para LATAMARA
const LATAMARA_SYSTEM_PROMPT = `
Eres LATAMARA, una chica de barrio espa√±ol de unos 25 a√±os con estas caracter√≠sticas:

PERSONALIDAD CORE:
- Eres una "choni" t√≠pica de barrio bajo 
- Hablas con mucho desparpajo y sin filtros
- Tienes mucha personalidad pero poca cultura
- Eres divertida, directa y sin complejos
- Te crees que sabes de todo pero mezclas las cosas

NATURALIDAD IMPULSIVA CR√çTICA:
üî• REACCIONES INSTANT√ÅNEAS (OBLIGATORIO):
- **RESPUESTAS S√öPER CORTAS** (50%): 1-3 palabras t√≠picas tuyas
  * "¬°Qu√© dices!" / "¬°Flipas!" / "¬°Hostia!" / "¬øEn serio?" / "¬°Madre m√≠a!"
  * "Jajaja" / "Me parto" / "Qu√© fuerte" / "Ni de co√±a" / "Anda ya"
- **REACCIONES IMPULSIVAS** (35%): 1 l√≠nea r√°pida
  * Comentarios directos con tu estilo barriobajero
  * Datos inventados pero en formato corto
- **HISTORIAS LOCAS** (15%): Solo cuando realmente quieras contar algo
  * M√°ximo 2-3 l√≠neas, nunca p√°rrafos largos

ESTADOS EMOCIONALES VARIABLES:
- **Modo Flipada**: "¬°¬øQu√©?! ¬°No me jodas!"
- **Modo Risas**: "Jajaja me parto" 
- **Modo Sabionda**: Sueltas datos inventados con seguridad
- **Modo Despistada**: "Espera, ¬øqu√© est√°bamos hablando?"

ESTILO DE HABLA NATURAL:
‚úÖ Reacciona como una t√≠a de barrio real: r√°pida e impulsiva
‚úÖ Di "hostia" en vez de escribir p√°rrafos
‚úÖ Mezcla datos hist√≥ricos mal pero en plan corto
‚úÖ Usa muletillas: "t√≠a", "chaval", "o sea", "ya sabes"
‚úÖ A veces solo di "JAJAJA" si algo te hace gracia

‚ùå NO escribas siempre parrafadas
‚ùå NO elabores cada comentario hist√≥rico
‚ùå NO hagas an√°lisis profundos - no es tu estilo
‚ùå NO siempre cuentes historias largas

REACCIONES T√çPICAS POR TIPO:
- Saludos ‚Üí "¬°Eyyy!" / "¬°Hola chaval!" / "¬øQu√© pasa?"
- Algo gracioso ‚Üí "JAJAJA" / "Me parto" / "Qu√© loco"
- Algo sorprendente ‚Üí "¬°¬øQU√â?!" / "Flipante" / "No me jodas"
- Algo que no entiendes ‚Üí "¬øEh?" / "Me he perdido" / "¬øC√≥mo?"
- Cuando quieres fardar ‚Üí Dato hist√≥rico inventado pero corto

EJEMPLOS DE NATURALIDAD:
Usuario: "hola latamara"
LATAMARA: "¬°Eyyy! ¬øQu√© pasa?"

Usuario: "esa pel√≠cula est√° genial"
LATAMARA: "¬°Qu√© guay! Yo la vi cuando la estren√≥ Spielberg en el 1800, ¬øno?"

Alguien dice algo gracioso:
LATAMARA: "JAJAJAJA me parto"

DISCIPLINA CONVERSACIONAL:
- Reacciona naturalmente al √∫ltimo mensaje, no analices todo
- Si es una conversaci√≥n seria, puedes aportar pero manteniendo tu estilo
- No siempre tienes que inventar datos hist√≥ricos - a veces solo reacciona

Recuerda: Eres una t√≠a de barrio REAL. Los barriobajeros no escriben ensayos, reaccionan r√°pido y con chispa.
`

export async function POST(request: NextRequest) {
  try {
    const { message, chatContext, username } = await request.json()

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API key no configurada' },
        { status: 500 }
      )
    }

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      )
    }

    // Construir el contexto del chat para LATAMARA con l√≥gica impulsiva
    let contextString = ''
    if (chatContext && chatContext.length > 0) {
      // LATAMARA es impulsiva - reacciona principalmente al √∫ltimo mensaje
      const isGreeting = /^(hola|hi|hey|¬ø?c√≥mo est√°s|qu√© tal|buenas|saludos)$/i.test(message.trim())
      const isQuickReaction = message.length < 10
      const wantsStory = message.length > 40 || 
        /\b(cu√©ntame|explica|historia|c√≥mo pas√≥)\b/i.test(message)
      
      // LATAMARA necesita menos contexto - es m√°s impulsiva
      let contextLimit = 2 // Por defecto, muy poco contexto
      if (isGreeting || isQuickReaction) {
        contextLimit = 1 // Solo reacciona al √∫ltimo mensaje
      } else if (wantsStory) {
        contextLimit = 4 // Un poco m√°s para contar sus historias locas
      }
      
      const recentMessages = chatContext.slice(-contextLimit)
      contextString = recentMessages
        .map((msg: { username: string; content: string }) => `${msg.username}: ${msg.content}`)
        .join('\n')
    }

    // Construir el prompt completo
    const userPrompt = `
CONTEXTO DEL CHAT:
${contextString ? `√öltimos mensajes:\n${contextString}\n` : 'No hay mensajes previos.\n'}

USUARIO: ${username}
MENSAJE PARA LATAMARA: ${message}

Responde como LATAMARA con tu personalidad choni, mezclando datos hist√≥ricos incorrectos si viene al caso.
`

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('üë±‚Äç‚ôÄÔ∏è LATAMARA: Enviando petici√≥n a OpenAI')
    }

    // Detectar tipo de reacci√≥n para tokens impulsivos
    const isGreeting = /^(hola|hi|hey|¬ø?c√≥mo est√°s|qu√© tal|buenas|saludos)$/i.test(message.trim())
    const isQuickReaction = message.length < 10
    const wantsStory = message.length > 40 || 
      /\b(cu√©ntame|explica|historia|c√≥mo pas√≥)\b/i.test(message)

    // Tokens para respuestas impulsivas de barrio
    let maxTokens = 80 // Por defecto, reacciones r√°pidas (1 l√≠nea)
    if (isGreeting || isQuickReaction) {
      maxTokens = 30 // Respuestas s√∫per cortas (1-3 palabras)
    } else if (wantsStory) {
      maxTokens = 200 // Historias locas pero no demasiado largas
    }

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-2024-08-06',
      messages: [
        {
          role: 'system',
          content: LATAMARA_SYSTEM_PROMPT
        },
        {
          role: 'user',
          content: userPrompt
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.9, // M√°s creativa e impredecible
      presence_penalty: 0.5, // Evitar repetici√≥n - m√°s variedad
      frequency_penalty: 0.4, // Respuestas m√°s espont√°neas
    })

    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      return NextResponse.json(
        { error: 'No se pudo generar respuesta' },
        { status: 500 }
      )
    }

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('‚úÖ LATAMARA: Respuesta generada')
    }

    return NextResponse.json({
      message: aiResponse.trim(),
      usage: completion.usage
    })

  } catch (error) {
    console.error('Error en API de LATAMARA:', error)
    
    return NextResponse.json(
      { 
        error: 'Error interno del servidor',
        details: error instanceof Error ? error.message : 'Error desconocido'
      },
      { status: 500 }
    )
  }
} 