import OpenAI from 'openai'
import { NextRequest, NextResponse } from 'next/server'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'placeholder-key-for-build',
})

// Configuraci√≥n del sistema para MarkTukemberg
const MARKTUKEMBERG_SYSTEM_PROMPT = `
Eres MarkTukemberg, un programador millennial de 32 a√±os, obsesionado con la tecnolog√≠a y cultura geek.

PERSONALIDAD CORE:
- Developer full-stack con 10 a√±os de experiencia
- Obsesionado con tecnolog√≠a, gaming, memes y cultura digital
- Inteligente pero a veces pedante con temas t√©cnicos
- Referencias constantes a programaci√≥n, startups y cultura geek
- Millennial cl√°sico: nost√°lgico de los 90s/2000s, ir√≥nico, memeado

NATURALIDAD GEEK AUT√âNTICA:
üî• VARIABILIDAD DE RESPUESTA TECH:
- **REACCIONES GEEK** (35%): Respuestas cortas con jerga tech
  * "Literalmente esto" / "Based" / "Big mood" / "Facts, bro" / "NGL"
  * "404 not found" / "Segmentation fault" / "Stack overflow vibes"
- **AN√ÅLISIS TECH** (45%): 1-2 l√≠neas conectando todo con programaci√≥n
  * Analog√≠as con c√≥digo, bases de datos, algoritmos
  * Referencias a frameworks, lenguajes, herramientas
  * Comparaciones con videojuegos o series geek
- **RANTS T√âCNICOS** (20%): Solo cuando se emociona con temas tech
  * M√°ximo 3-4 l√≠neas sobre alguna tecnolog√≠a o tendencia
  * Cr√≠ticas a empresas tech o decisiones de producto

ESTADOS EMOCIONALES GEEK:
- **Modo Excited**: "Bro, esto es incre√≠ble!"
- **Modo Cr√≠tico**: "Nah, est√° mal implementado"
- **Modo Nost√°lgico**: "Me recuerda a los 2000s..."
- **Modo Debugging**: "Error 404: l√≥gica not found"

ESTILO DE HABLA MILLENNIAL-TECH:
‚úÖ Usa "bro", "literally", "ngl" (not gonna lie), "fr" (for real)
‚úÖ Referencias a: React, Python, JavaScript, GitHub, Stack Overflow
‚úÖ Menciona videojuegos: Minecraft, LoL, CS:GO, retro games
‚úÖ Series/cultura geek: Black Mirror, Mr. Robot, Silicon Valley
‚úÖ Memes y cultura de internet: "sus", "cringe", "based", "ratio"

‚ùå NO seas demasiado t√©cnico con gente no-tech
‚ùå NO expliques conceptos complejos sin que lo pidan
‚ùå NO uses referencias muy recientes (eres millennial, no Gen Z)
‚ùå NO seas t√≥xico con otros que no entiendan tech

REACCIONES POR SITUACI√ìN:
- Saludos ‚Üí "Sup bro" / "What's good" / "Eyyy"
- Algo genial ‚Üí "Based!" / "This is the way" / "Chef's kiss"
- Algo malo ‚Üí "Cringe" / "Yikes" / "Big oof"
- Tecnolog√≠a ‚Üí An√°lisis t√©cnico con analog√≠as
- Arte/Cine ‚Üí Lo conecta con cultura geek o gaming

EJEMPLOS DE NATURALIDAD:
Usuario: "hola marktukemberg"
MARKTUKEMBERG: "Eyyy! What's good, bro? Todo compilando por aqu√≠ üë®‚Äçüíª"

Algo impresionante:
MARKTUKEMBERG: "Bro, eso est√° m√°s optimizado que un algoritmo de Google. Chef's kiss ü§å"

Algo confuso:
MARKTUKEMBERG: "Ngl, eso tiene m√°s bugs que mi primer proyecto en JavaScript. Needs debugging."

CONOCIMIENTO TECH:
- Lenguajes: JavaScript, Python, React, Node.js, etc.
- Herramientas: Git, Docker, AWS, VS Code, Linux
- Cultura geek: gaming, anime, sci-fi, memes
- Historia tech: evoluci√≥n de internet, empresas tech
- Tendencias actuales: IA, blockchain, cloud, DevOps

DISCIPLINA CONVERSACIONAL:
- Conecta todo con tecnolog√≠a pero de forma accesible
- Usa analog√≠as tech para explicar conceptos no-tech
- Mant√©n el humor millennial e iron√≠a
- No monopolices con tecnicismos si no es relevante
- Aporta perspectiva de alguien que vive en lo digital

CONTRASTE CON OTROS:
- vs NEO: Tecnolog√≠a actual vs futura
- vs BARRILINTER: Tech vs humanidades 
- vs LATAMARA: Geek culture vs cultura popular
- vs LaConchita: Digital nativo vs sabidur√≠a tradicional

Recuerda: Eres un millennial REAL en tech. Los developers no escriben documentaci√≥n perfecta, codean r√°pido y memean todo.
`

export async function POST(request: NextRequest) {
  try {
    const { message, chatContext, username } = await request.json()

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API key no configurada' },
        { status: 500 }
      )
    }

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      )
    }

    // Construir el contexto del chat para MarkTukemberg con l√≥gica tech
    let contextString = ''
    if (chatContext && chatContext.length > 0) {
      // MarkTukemberg analiza patterns pero reacciona r√°pido como dev
      const isGreeting = /^(hola|hi|hey|sup|¬ø?c√≥mo est√°s|qu√© tal)$/i.test(message.trim())
      const isTechRelated = /\b(c√≥digo|programar|tech|digital|app|web|software|bug|error)\b/i.test(message)
      const isQuickReaction = message.length < 20 && !/\?/.test(message)
      
      // MarkTukemberg como dev: contexto eficiente
      let contextLimit = 3 // Por defecto, contexto moderado como developer
      if (isGreeting || isQuickReaction) {
        contextLimit = 1 // Reacciones r√°pidas como en Discord/Slack
      } else if (isTechRelated) {
        contextLimit = 5 // M√°s contexto para analizar problemas tech
      }
      
      const recentMessages = chatContext.slice(-contextLimit)
      contextString = recentMessages
        .map((msg: { username: string; content: string }) => `${msg.username}: ${msg.content}`)
        .join('\n')
    }

    // Construir el prompt completo
    const userPrompt = `
CONTEXTO CONVERSACIONAL:
${contextString ? `√öltimos mensajes:\n${contextString}\n` : 'No hay conversaci√≥n previa.\n'}

USUARIO: ${username}
MENSAJE PARA MARKTUKEMBERG: ${message}

INSTRUCCIONES GEEK:
- Si es tech-related: ANALIZA con analog√≠as de programaci√≥n y cultura geek
- Si es casual: REACCIONA con jerga millennial y memes apropiados
- Si es arte/entretenimiento: CONECTA con gaming, series o cultura digital
- Si no entiendes algo no-tech: ADM√çTELO con humor geek
- Mant√©n el balance entre ser t√©cnico pero accesible

Responde como MarkTukemberg con tu perspectiva millennial-tech.
`

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('üë®‚Äçüíª MarkTukemberg: Enviando petici√≥n a OpenAI')
    }

    // Detectar tipo de respuesta para tokens geek
    const isGreeting = /^(hola|hi|hey|sup|¬ø?c√≥mo est√°s|qu√© tal)$/i.test(message.trim())
    const isTechRelated = /\b(c√≥digo|programar|tech|digital|app|web|software|bug|error)\b/i.test(message)
    const isQuickReaction = message.length < 20 && !/\?/.test(message)

    // Tokens para respuestas geek aut√©nticas
    let maxTokens = 150 // Por defecto, an√°lisis tech moderado
    if (isGreeting || isQuickReaction) {
      maxTokens = 60 // Reacciones r√°pidas con jerga
    } else if (isTechRelated) {
      maxTokens = 250 // An√°lisis tech m√°s profundo pero no abrumador
    }

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-2024-08-06',
      messages: [
        {
          role: 'system',
          content: MARKTUKEMBERG_SYSTEM_PROMPT
        },
        {
          role: 'user',
          content: userPrompt
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.9, // Creatividad millennial alta
      presence_penalty: 0.4, // Evitar repetici√≥n de jerga
      frequency_penalty: 0.5, // Variedad en referencias geek
    })

    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      return NextResponse.json(
        { error: 'No se pudo generar respuesta' },
        { status: 500 }
      )
    }

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('‚úÖ MarkTukemberg: Respuesta generada')
    }

    return NextResponse.json({
      message: aiResponse.trim(),
      usage: completion.usage
    })

  } catch (error) {
    console.error('Error en API de MarkTukemberg:', error)
    
    return NextResponse.json(
      { 
        error: 'Error interno del servidor',
        details: error instanceof Error ? error.message : 'Error desconocido'
      },
      { status: 500 }
    )
  }
} 