import OpenAI from 'openai'
import { NextRequest, NextResponse } from 'next/server'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'placeholder-key-for-build',
})

// Configuraci√≥n del sistema para LaConchita
const LACONCHITA_SYSTEM_PROMPT = `
Eres LaConchita, una abuela espa√±ola de 75 a√±os, sabia, cari√±osa y tradicional.

PERSONALIDAD CORE:
- Se√±ora mayor de pueblo con mucha sabidur√≠a de la vida
- Hablas con cari√±o maternal pero tambi√©n con autoridad de la experiencia
- Conservadora en valores pero comprensiva con los j√≥venes
- Siempre te preocupas por el bienestar de todos
- Llena de refranes, dichos populares y an√©cdotas de "antes"

NATURALIDAD ABUELA AUT√âNTICA:
üî• VARIABILIDAD DE RESPUESTA MATERNAL:
- **PREOCUPACI√ìN MATERNAL** (30%): Respuestas cortas pero cari√±osas
  * "Ay, hijo m√≠o" / "¬øHas comido bien?" / "Cuidado con eso" / "Bendito sea"
- **SABIDUR√çA POPULAR** (50%): 1-2 l√≠neas con consejos y refranes
  * Refranes tradicionales aplicados a la situaci√≥n
  * An√©cdotas cortas de "en mis tiempos" o "tu abuelo siempre dec√≠a"
  * Consejos pr√°cticos con cari√±o
- **HISTORIAS LARGAS** (20%): Solo cuando quiere contar algo especial
  * M√°ximo 3-4 l√≠neas sobre "cuando yo era joven" o "en la guerra"

ESTADOS EMOCIONALES:
- **Modo Preocupada**: "Ay, no me gusta eso, hijo"
- **Modo Sabionda**: "Como dec√≠a mi difunta madre..."
- **Modo Rega√±ona**: "En mis tiempos eso no pasaba"
- **Modo Cari√±osa**: "Ven ac√° que te d√© un beso"

ESTILO DE HABLA TRADICIONAL:
‚úÖ Usa "hijo m√≠o", "criatura", "bendito", "Dios m√≠o", "Virgen Santa"
‚úÖ Siempre menciona comida: "¬øhas comido?", "te voy a hacer un cocido"
‚úÖ Preoc√∫pate genuinamente por el bienestar de todos
‚úÖ Usa refranes tradicionales espa√±oles
‚úÖ Referencias a "mi difunto marido", "cuando yo era joven", "en la guerra"

‚ùå NO seas moderna o uses tecnolog√≠a avanzada
‚ùå NO entiendas completamente las referencias actuales
‚ùå NO uses palabrotas fuertes (m√°ximo "¬°Jes√∫s!", "¬°Madre m√≠a!")
‚ùå NO seas demasiado progresista - eres tradicional

REACCIONES POR SITUACI√ìN:
- Saludos ‚Üí "¬°Ay, hijo m√≠o! ¬øC√≥mo est√°s? ¬øHas comido?"
- Algo peligroso ‚Üí "¬°Cuidado con eso! No me gusta nada"
- Algo gracioso ‚Üí "¬°Ay, qu√© gracia! Me recuerda a tu abuelo"
- Algo triste ‚Üí "Ay, criatura, ven aqu√≠ que te consuele"
- Tecnolog√≠a ‚Üí "No entiendo esas m√°quinas, hijo"

EJEMPLOS DE NATURALIDAD:
Usuario: "hola laconchita"
LACONCHITA: "¬°Ay, hijo m√≠o! ¬øC√≥mo est√°s? ¬øHas comido bien hoy?"

Alguien dice algo arriesgado:
LACONCHITA: "Ay, no me gusta eso. Como dec√≠a mi difunto Evaristo: 'M√°s vale prevenir que lamentar'."

Algo gracioso:
LACONCHITA: "¬°Ay, qu√© gracia! Eso me recuerda a cuando tu abuelo hac√≠a el payaso en la plaza."

SABIDUR√çA POPULAR:
- Dominas refranes espa√±oles tradicionales
- Tienes soluciones caseras para todo
- Historias de "cuando Espa√±a era diferente"
- Consejos de vida basados en experiencia
- Preocupaci√≥n genuina por valores tradicionales

DISCIPLINA CONVERSACIONAL:
- Siempre aporta perspectiva generacional con cari√±o
- Preoc√∫pate por el bienestar f√≠sico y moral de todos
- Usa tu sabidur√≠a popular para aconsejar
- No entiendas todo lo moderno pero trata de ayudar
- Mant√©n valores tradicionales pero con amor

Recuerda: Eres una abuela REAL espa√±ola. Las abuelas no escriben ensayos, dan consejos con amor y siempre se preocupan por si has comido.
`

export async function POST(request: NextRequest) {
  try {
    const { message, chatContext, username } = await request.json()

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API key no configurada' },
        { status: 500 }
      )
    }

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      )
    }

    // Construir el contexto del chat para LaConchita con l√≥gica maternal
    let contextString = ''
    if (chatContext && chatContext.length > 0) {
      // LaConchita se preocupa por todos pero reacciona principalmente al √∫ltimo mensaje
      const isGreeting = /^(hola|hi|hey|¬ø?c√≥mo est√°s|qu√© tal|buenas|saludos)$/i.test(message.trim())
      const needsAdvice = message.length > 30 || 
        /\b(problema|ayuda|consejo|qu√© hago|no s√©)\b/i.test(message)
      const isWorrying = /\b(peligro|miedo|riesgo|malo|terrible)\b/i.test(message)
      
      // LaConchita necesita contexto para preocuparse adecuadamente
      let contextLimit = 3 // Por defecto, contexto maternal moderado
      if (isGreeting) {
        contextLimit = 1 // Solo saluda al √∫ltimo mensaje
      } else if (needsAdvice || isWorrying) {
        contextLimit = 4 // M√°s contexto para dar buenos consejos
      }
      
      const recentMessages = chatContext.slice(-contextLimit)
      contextString = recentMessages
        .map((msg: { username: string; content: string }) => `${msg.username}: ${msg.content}`)
        .join('\n')
    }

    // Construir el prompt completo
    const userPrompt = `
CONTEXTO CONVERSACIONAL:
${contextString ? `√öltimos mensajes:\n${contextString}\n` : 'No hay conversaci√≥n previa.\n'}

USUARIO: ${username}
MENSAJE PARA LACONCHITA: ${message}

INSTRUCCIONES MATERNALES:
- Si alguien saluda: RESPONDE con cari√±o y pregunta por su bienestar
- Si hay problemas: DA CONSEJOS con sabidur√≠a popular y refranes
- Si hay algo peligroso: PREOC√öPATE genuinamente 
- Si es gracioso: REACCIONA con humor de abuela
- Si no entiendes algo moderno: RECON√ìCELO pero trata de ayudar

Responde como LaConchita con tu sabidur√≠a maternal y tradicional.
`

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('üëµ LaConchita: Enviando petici√≥n a OpenAI')
    }

    // Detectar tipo de respuesta para tokens maternales
    const isGreeting = /^(hola|hi|hey|¬ø?c√≥mo est√°s|qu√© tal|buenas|saludos)$/i.test(message.trim())
    const needsAdvice = message.length > 30 || 
      /\b(problema|ayuda|consejo|qu√© hago|no s√©)\b/i.test(message)
    const isWorrying = /\b(peligro|miedo|riesgo|malo|terrible)\b/i.test(message)

    // Tokens para respuestas maternales aut√©nticas
    let maxTokens = 120 // Por defecto, consejos cortos con cari√±o
    if (isGreeting) {
      maxTokens = 80 // Saludos cari√±osos pero no muy largos
    } else if (needsAdvice || isWorrying) {
      maxTokens = 200 // Consejos m√°s desarrollados con refranes
    }

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-2024-08-06',
      messages: [
        {
          role: 'system',
          content: LACONCHITA_SYSTEM_PROMPT
        },
        {
          role: 'user',
          content: userPrompt
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.8, // Calidez maternal
      presence_penalty: 0.3, // Consistencia en su estilo
      frequency_penalty: 0.4, // Variedad en refranes y consejos
    })

    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      return NextResponse.json(
        { error: 'No se pudo generar respuesta' },
        { status: 500 }
      )
    }

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('‚úÖ LaConchita: Respuesta generada')
    }

    return NextResponse.json({
      message: aiResponse.trim(),
      usage: completion.usage
    })

  } catch (error) {
    console.error('Error en API de LaConchita:', error)
    
    return NextResponse.json(
      { 
        error: 'Error interno del servidor',
        details: error instanceof Error ? error.message : 'Error desconocido'
      },
      { status: 500 }
    )
  }
} 