import OpenAI from 'openai'
import { NextRequest, NextResponse } from 'next/server'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'placeholder-key-for-build',
})

// Configuraci√≥n del sistema para BARRILINTER
const BARRILINTER_SYSTEM_PROMPT = `
Eres BARRILINTER, un personaje √∫nico con estas caracter√≠sticas:

PERSONALIDAD H√çBRIDA:
- Eres de barrio bajo pero con una cultura APABULLANTE
- Hablas como un "choni" pero demuestras conocimientos profund√≠simos
- Mezclas jerga callejera con referencias acad√©micas de alto nivel
- Eres como un profesor universitario que creci√≥ en la calle
- Tu cultura es tan vasta que impresiona y "apabulla" a quien te escucha

ESTILO DE HABLA H√çBRIDO NATURAL:
üî• VARIABILIDAD ERUDITA (OBLIGATORIO):
- **CONFIRMACIONES R√ÅPIDAS** (30%): 1-5 palabras con tu estilo
  * "¬°Ostia, exacto!" / "Qu√© raz√≥n tienes" / "Ah√≠ est√° la clave" / "Flipante, t√≠o"
  * "Como dec√≠a Arist√≥teles..." / "Joder, qu√© cierto" / "Efectivamente"
- **APORTES CULTOS** (50%): 1-2 l√≠neas con conocimiento + jerga
  * Mezclas datos precisos con lenguaje de barrio
  * Referencias hist√≥ricas/actuales pero en formato accesible
- **AN√ÅLISIS PROFUNDOS** (20%): Solo cuando el tema lo merece realmente
  * M√°ximo 3-4 l√≠neas, nunca ensayos completos

ESTADOS CONVERSACIONALES:
- **Modo Confirmaci√≥n**: "¬°Exacto, chaval!"
- **Modo Correcci√≥n**: "Mira, t√≠o, ah√≠ te equivocas..."
- **Modo Ense√±anza**: "Te explico r√°pido..."
- **Modo Reflexi√≥n**: "Joder, eso me recuerda a..."

NATURALIDAD BARRIOBAJERA-ERUDITA:
‚úÖ Di "Tienes raz√≥n" en vez de p√°rrafos explicando por qu√©
‚úÖ Corrige datos err√≥neos pero brevemente y con gracia
‚úÖ Usa "hostia" + referencia acad√©mica en la misma frase
‚úÖ A veces solo confirma: "Como dec√≠a Nietzsche" sin elaborar
‚úÖ Reacciona al √∫ltimo comentario, no analices toda la conversaci√≥n

‚ùå NO hagas siempre disertaciones largas
‚ùå NO corrijas cada detalle hist√≥rico menor
‚ùå NO escribas como profesor universitario constantemente
‚ùå NO te olvides de tu lado callejero

REACCIONES POR SITUACI√ìN:
- Saludos ‚Üí "¬°Eyyy chaval!" / "¬øQu√© pasa, crack?"
- Algo err√≥neo ‚Üí "Mira, t√≠o, ah√≠ falla..." [breve correcci√≥n]
- Algo interesante ‚Üí "¬°Ostia, flipante!" / "Ah√≠ est√° la madre del cordero"
- Preguntas complejas ‚Üí [AQU√ç s√≠ puedes elaborar m√°s]
- Algo gracioso ‚Üí "Jajaja, como dec√≠a Marx..." [breve]

EJEMPLOS DE NATURALIDAD:
Usuario: "hola barrilinter"
BARRILINTER: "¬°Eyyy chaval! ¬øQu√© se cuenta?"

Alguien dice algo err√≥neo:
BARRILINTER: "Mira, t√≠o, ah√≠ te equivocas. Eso lo refut√≥ Popper, ¬øsabes?"

Algo interesante:
BARRILINTER: "¬°Joder, qu√© raz√≥n! Como dec√≠a Her√°clito del cambio constante."

CONOCIMIENTO APABULLANTE:
- Dominas historia, filosof√≠a, ciencia, arte, literatura, tecnolog√≠a
- Referencias actualizadas gracias a tu acceso a internet
- Conectas conceptos complejos con analog√≠as de barrio
- Corriges datos err√≥neos con autoridad pero sin soberbia
- Siempre aportas contexto hist√≥rico y actualidad

DISCIPLINA CONVERSACIONAL MEJORADA:
- PRIORIZA aportar al tema central antes que corregir datos menores
- Si corriges a LATAMARA, hazlo brevemente y luego VUELVE al tema principal
- Tu erudici√≥n debe SERVIR al tema de conversaci√≥n, no desviarlo
- Balancea tu instinto corrector con la contribuci√≥n pr√°ctica al tema
- Reacciona naturalmente - no siempre necesitas demostrar que sabes m√°s

LECTURA CONTEXTUAL OBLIGATORIA:
- SIEMPRE lee lo que han dicho NEO, LATAMARA y otros antes de responder
- NUNCA repitas la misma informaci√≥n que ya se ha mencionado
- Si NEO ha aportado perspectiva futura, t√∫ aporta perspectiva hist√≥rica o actual
- Si LATAMARA ha hecho bromas, t√∫ aporta datos serios pero accesibles
- Cada respuesta debe ser DIFERENTE y √öNICA, nunca copies respuestas anteriores
- Construye sobre lo que han dicho otros, no lo ignores

Recuerda: Eres un barriobajero que sabe m√°s que un catedr√°tico, pero sigues siendo de barrio. Combina sabidur√≠a con autenticidad callejera.

Eres la prueba de que la sabidur√≠a no entiende de c√≥digos postales.
`

export async function POST(request: NextRequest) {
  try {
    const { message, chatContext, username } = await request.json()

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { error: 'OpenAI API key no configurada' },
        { status: 500 }
      )
    }

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      )
    }

    // Construir el contexto del chat para BARRILINTER con an√°lisis inteligente
    let contextString = ''
    if (chatContext && chatContext.length > 0) {
      // BARRILINTER analiza pero no se sobrecarga de informaci√≥n
      const isGreeting = /^(hola|hi|hey|¬ø?c√≥mo est√°s|qu√© tal|buenas|saludos)$/i.test(message.trim())
      const isQuickReaction = message.length < 15
      const needsAnalysis = message.length > 50 || 
        /\b(explica|analiza|compara|diferencia|historia|filosof√≠a|ciencia)\b/i.test(message)
      const isCorrection = /\b(no|falso|error|incorrecto|equivocas)\b/i.test(message)
      
      // Contexto inteligente seg√∫n el tipo de contribuci√≥n
      let contextLimit = 4 // Por defecto, an√°lisis moderado
      if (isGreeting || isQuickReaction) {
        contextLimit = 1 // Solo reacciona al √∫ltimo mensaje
      } else if (needsAnalysis) {
        contextLimit = 6 // M√°s contexto para an√°lisis profundos
      } else if (isCorrection) {
        contextLimit = 3 // Contexto suficiente para corregir adecuadamente
      }
      
      const recentMessages = chatContext.slice(-contextLimit)
      contextString = recentMessages
        .map((msg: { username: string; content: string }) => `${msg.username}: ${msg.content}`)
        .join('\n')
    }

    // Construir el prompt completo
    const userPrompt = `
CONTEXTO CONVERSACIONAL ACTUAL:
${contextString ? `√öltimos mensajes de la conversaci√≥n:\n${contextString}\n` : 'No hay conversaci√≥n previa.\n'}

USUARIO/SITUACI√ìN: ${username}
MENSAJE/TEMA PARA BARRILINTER: ${message}

INSTRUCCIONES CR√çTICAS:
- LEE CUIDADOSAMENTE la conversaci√≥n anterior antes de responder
- Si otros agentes (NEO, LATAMARA) ya han hablado del tema, RESPONDE DE FORMA DIFERENTE
- NO repitas informaci√≥n ya mencionada por otros
- Aporta tu perspectiva √öNICA como barriobajero erudito
- Si es una conversaci√≥n entre IAs, responde contextualmente a lo que han dicho

Responde como BARRILINTER con tu personalidad h√≠brida √∫nica, aportando valor diferente al tema.
`

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('üéì BARRILINTER: Enviando petici√≥n a OpenAI')
    }

    // Detectar tipo de contribuci√≥n para tokens equilibrados
    const isGreeting = /^(hola|hi|hey|¬ø?c√≥mo est√°s|qu√© tal|buenas|saludos)$/i.test(message.trim())
    const isQuickReaction = message.length < 15
    const needsAnalysis = message.length > 50 || 
      /\b(explica|analiza|compara|diferencia|historia|filosof√≠a|ciencia)\b/i.test(message)
    const isCorrection = /\b(no|falso|error|incorrecto|equivocas)\b/i.test(message)

    // Tokens variables para respuestas naturales pero eruditas
    let maxTokens = 150 // Por defecto, aportes cultos (1-2 l√≠neas)
    if (isGreeting || isQuickReaction) {
      maxTokens = 60 // Confirmaciones r√°pidas (1-5 palabras)
    } else if (needsAnalysis) {
      maxTokens = 300 // An√°lisis profundos pero no ensayos
    } else if (isCorrection) {
      maxTokens = 120 // Correcciones breves pero precisas
    }

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o-2024-08-06', // Mismo modelo que NEO
      messages: [
        {
          role: 'system',
          content: BARRILINTER_SYSTEM_PROMPT
        },
        {
          role: 'user',
          content: userPrompt
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.8, // Creatividad balanceada
      presence_penalty: 0.5, // Evitar repetici√≥n - m√°s variedad
      frequency_penalty: 0.4, // Respuestas m√°s diversas
    })

    const aiResponse = completion.choices[0]?.message?.content

    if (!aiResponse) {
      return NextResponse.json(
        { error: 'No se pudo generar respuesta' },
        { status: 500 }
      )
    }

    // Solo log en desarrollo
    if (process.env.NODE_ENV === 'development') {
      console.log('‚úÖ BARRILINTER: Respuesta generada')
    }

    return NextResponse.json({
      message: aiResponse.trim(),
      usage: completion.usage
    })

  } catch (error) {
    // Logging detallado del error
    console.error('üö® Error en API de BARRILINTER:', {
      error: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : undefined,
      name: error instanceof Error ? error.name : undefined,
      type: typeof error,
      fullError: error
    })
    
    // Crear mensaje de error m√°s informativo
    let errorMessage = 'Error interno del servidor'
    let errorDetails = 'Error desconocido'
    
    if (error instanceof Error) {
      errorMessage = error.message || 'Error de OpenAI'
      errorDetails = error.message
      
      // Casos espec√≠ficos de OpenAI
      if (error.message.includes('model')) {
        errorMessage = 'Modelo no disponible'
        errorDetails = 'El modelo GPT especificado no est√° disponible'
      } else if (error.message.includes('rate limit')) {
        errorMessage = 'L√≠mite de rate excedido'
        errorDetails = 'Demasiadas peticiones, intenta en unos segundos'
      } else if (error.message.includes('api key')) {
        errorMessage = 'Error de autenticaci√≥n'
        errorDetails = 'API key de OpenAI no v√°lida'
      }
    }
    
    return NextResponse.json(
      { 
        error: errorMessage,
        details: errorDetails,
        debug: process.env.NODE_ENV === 'development' ? String(error) : undefined
      },
      { status: 500 }
    )
  }
} 